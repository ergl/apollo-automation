{run_template, "run.config.template"}.
% {run_template, "erlang_run.config.template"}.
{cluster_template, "cluster.config.template"}.

{load_configuration, #{
    key_limit => 1_000_000,
    %% size of value in bytes
    val_size => 256
}}.

%% Syntax for each experiment:
#{
    %% Number of threads per client machine.
    %% Allowed values are numbers (like `1`, `20`, etc), list of numbers,
    %% or a MFA ({M, F, A}) that in the end produces a generator of numbers
    %% For example, the line below produces the list [0, 50, 100]
    %% NOTE: The minimum number of workers is 1. All values less than 1 will be set to 1.
    clients => {lists, seq, [0, 100, 50]},

    %% The folder name under $HOME/results where all results for this test will go
    results_folder => "test_name",

    %% A map of template subsitutions.
    %% Check run.config.template for available values.
    %% In essence, anything present below will be changed in the corresponding
    %% run.config file supplied to the benchmark.
    %% Any key will be overriden, but the minimum amount of keys to be present
    %% is shown below.
    run_with => #{
        %% Use a simple list of operations `[read, update, ...]`
        %% for a sequence of operations that will execute randomly with equal probability
        %% Use a weighted list like `[{read, 0.9}, {update, 0.1}]`
        %% to execute 90% reads, 10% updates
        operations => [read],
        readonly_ops => 1,
        retry_aborts => false,
        %% Valid values: uniform, {uniform_exclude, Key}, pareto, {biased_key, Key, Bias}, {biased_key_worker_id, Key, Bias}, {constant_key, Key} Uniform is default if omitted
        %% For biased_key and biased_key_worker_id, bias is expressed as a floating point between 0 and 1
        key_distribution => uniform
    },

    %% A map of config template subsitutions.
    %% Check cluster.config.template for available values.
    %% For the `clusters` key, you can either input a list of replica names,
    %% or a raw map like we used in old cluster.config files
    %%
    %% For the `leaders` key, you can put either a map from partition number
    %% to replica name, or a single replica name, in which case it will
    %% be used as the replica for every partition. If the `leaders` key is
    %% omitted, then a replica will be used at random.
    run_on => #{
        ext_tag => "release-X.Y.Z",
        clusters => [virginia],
        partitions => 1,
        %% This can be a number, or the `auto` atom, in which case it will
        %% allocate client machines automatically uniformly across all partitions,
        %% using all the available machines.
        per_partition => 4
    },

    %% When testing recovery, one can specify here a map of failure events
    %%
    %% Each replica can be paired with a (whole data center) failure, or
    %% failures to specific machines.
    %%
    %% - To specify a whole data center crash, use `replicaName => timeSpec`
    %% - To specify a specific partition, use `{replicaName, Partition} => timeSpec`
    failures_after => #{
        virginia => {minutes, 2},
        {california, 0} => {minutes, 2}
    },

    %% When using the crasher script, specify the arguments here
    %% -commitTimeout, -crashKey, -master_ip, -master_port, -opTimeout and -value_bytes
    %% will be derived from other parts of the configuration, although
    %% -opTimeout and -commitTimeout can be overriden by specifying them too
    %%
    %% One can also specify retries for the transaction, by using the `retries`
    %% key.
    crasher_after => #{
        replica => virginia,
        hot_key => 0,
        at => {minutes, 2}
    }
}.

{experiments,
    [
        % Test crasher script (spanner and multishot)
        % In this test, transactions only update one key, and will hit the hot_key with 1% probability.
        % What we want to see in this experiment is Spanner having higher throughput than Multishot
        % while recovery is taking place:
        %
        % 1. All the transactions at the crashing partition will block, lowering throughput by half
        % 2. In addition, at the healthy partition, some percentage of transactions will be blocked
        %    by the crasher transaction, lowering throughput even more.
        %
        % Point (2) should only be a problem in Multishot, since Spanner can proactively abort
        % the transaction if it waits too long.
        #{
            results_folder => "0_7_8_multishot_ycsb_a",
            clients => [0, 100, 500, 1000, 2000, 4000],
            run_on => #{
                ext_tag => "release-0.7.8",
                leaders => virginia,
                clusters => [virginia, california, frankfurt],
                latencies => #{
                    virginia => [{california, 30}, {frankfurt, 30}],
                    california => [{virginia, 30}, {frankfurt, 30}],
                    frankfurt => [{virginia, 30}, {california, 30}]
                },
                partitions => 2,
                per_partition => 1,
                use_veleta => false,
                %% Ensure no TTL aborts
                txn_ttl => {minutes, 20}
            },
            run_with => #{
                duration => 5,
                report_interval => {seconds, 5},
                key_range => 1000000,
                operations => [{read, 0.5}, {update, 0.5}],
                readonly_ops => 1,
                writeonly_ops => 1,
                retry_aborts => false,
                key_distribution => {zipfian, 0.5},
                op_timeout => {minutes, 1},
                commit_timeout => {minutes, 1}
            }
        },
        #{
            results_folder => "0_7_8_spanner_ycsb_a",
            clients => [0, 100, 500, 1000, 2000, 4000],
            run_on => #{
                ext_tag => "release-0.7.8",
                leaders => virginia,
                clusters => [virginia, california, frankfurt],
                latencies => #{
                    virginia => [{california, 30}, {frankfurt, 30}],
                    california => [{virginia, 30}, {frankfurt, 30}],
                    frankfurt => [{virginia, 30}, {california, 30}]
                },
                partitions => 2,
                per_partition => 1,
                use_veleta => false,
                %% Ensure no TTL aborts
                txn_ttl => {minutes, 20},
                commit_protocol => spanner,
                %% No proactive aborts
                spanner_abort_interval => {minutes, 10}
            },
            run_with => #{
                duration => 5,
                report_interval => {seconds, 5},
                key_range => 1000000,
                operations => [{read, 0.5}, {update, 0.5}],
                readonly_ops => 1,
                writeonly_ops => 1,
                retry_aborts => false,
                key_distribution => {zipfian, 0.5},
                op_timeout => {minutes, 1},
                commit_timeout => {minutes, 1}
            }
        }
    ]
}.
